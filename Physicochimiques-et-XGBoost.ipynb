{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5V1Iy6d1yjD",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. Bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install pandas\n",
    "#!pip install zstandard\n",
    "!pip install geopandas\n",
    "!pip install seaborn\n",
    "!pip install plotly\n",
    "!pip install zstandard\n",
    "!pip install nbformat\n",
    "!pip install -U kaleido\n",
    "!pip install scikit-learn==1.5.2\n",
    "!pip install xgboost\n",
    "!pip install --upgrade scikit-learn xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13810,
     "status": "ok",
     "timestamp": 1734096975386,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "cgOmVL6i1yjL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import shapely.geometry as geom\n",
    "import plotly.express as px\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15896,
     "status": "ok",
     "timestamp": 1734096991257,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "EykuK7_K_EkQ",
    "outputId": "0d0014c9-a2c0-4d41-b7d1-b3d68657652a"
   },
   "outputs": [],
   "source": [
    "!pip install zstandard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naAO3l7Q1yjN",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2. Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 89405,
     "status": "ok",
     "timestamp": 1734097080624,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "bab8ncRa2Hpf",
    "outputId": "1a10b8b9-9673-4f03-afeb-abba89848a20"
   },
   "outputs": [],
   "source": [
    "#nécessaire si fichiers sur google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1734097080624,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "wZm9wt6k2PkY"
   },
   "outputs": [],
   "source": [
    "root_path = \"/content/drive/MyDrive/Master/S3/SDA-E/Projet/données/\"\n",
    "#naiades_path = root_path+\"naiades/\" # à changer avec le bon chemin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECLofEts1yjN"
   },
   "source": [
    "### 1. Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = pd.read_csv(\"donnees/stations_hb.csv.zst\",sep=';',escapechar = '\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1214,
     "status": "ok",
     "timestamp": 1734097081822,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "lluTdv3a1yjN"
   },
   "outputs": [],
   "source": [
    "# df_stations= pd.read_csv(root_path+\"stations_hb.csv.zst\",sep=';',escapechar = '\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1734097081822,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "eLkuPfpM1yjO",
    "outputId": "3c47bddf-d1dc-4902-af1f-4227b7a4addc"
   },
   "outputs": [],
   "source": [
    "df_stations.head()\n",
    "#df_station.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdmbQduW1yjP"
   },
   "source": [
    "### 2. Données physico-chimiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=\"donnees/donnees_physicochimie.csv.zst\"\n",
    "pc_sample = pd.read_csv(f,nrows=1)\n",
    "pc_list_cols = pc_sample.columns\n",
    "pc_list_cat = pc_list_cols[pc_list_cols.str.startswith((\n",
    "    'Lb','Nom','Mnemo',\n",
    "    'Cd','Sym','Com'))]\n",
    "\n",
    "pc_dict_cat = {col: 'category' for col in pc_list_cat}\n",
    "\n",
    "df_pc = pd.read_csv(\n",
    "        f,\n",
    "        sep=',',\n",
    "        engine='c',\n",
    "        escapechar='\\\\',\n",
    "        dtype=pc_dict_cat,\n",
    "        parse_dates=[7],\n",
    "        iterator=False)\n",
    "\n",
    "df_hb = pd.read_csv(\"donnees/donnees_hydrobio.csv.zst\",sep=',',escapechar = '\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 263,
     "status": "ok",
     "timestamp": 1734097082072,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "mnsHcAJ91yjQ"
   },
   "outputs": [],
   "source": [
    "# pc_sample= pd.read_csv(root_path+ \"donnees_physicochimie.csv.zst\",nrows=1)\n",
    "# pc_list_cols = pc_sample.columns\n",
    "# pc_list_cat = pc_list_cols[pc_list_cols.str.startswith((\n",
    "#     'Lb','Nom','Mnemo',\n",
    "#     'Cd','Sym','Com'))]\n",
    "# pc_dict_cat = {col: 'category' for col in pc_list_cat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 195426,
     "status": "ok",
     "timestamp": 1734097277742,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "bHipoDkb1yjQ"
   },
   "outputs": [],
   "source": [
    "# df_pc = pd.read_csv(root_path+\n",
    "#         \"donnees_physicochimie.csv.zst\",\n",
    "#         sep=',',\n",
    "#         engine='c',\n",
    "#         escapechar='\\\\',\n",
    "#         dtype=pc_dict_cat,\n",
    "#         parse_dates=[7],\n",
    "#         iterator=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1734097277746,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "J9T-SYBk1yjR",
    "outputId": "572155b8-0a24-49d0-9577-8c426f92dfac"
   },
   "outputs": [],
   "source": [
    "df_pc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 2362,
     "status": "ok",
     "timestamp": 1734097280087,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "NYL4pWMECx_J",
    "outputId": "af76331a-9ceb-4ce5-d0db-3e49760df2b3"
   },
   "outputs": [],
   "source": [
    "df_pc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1734097280087,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "o9TzI3sX1yjR",
    "outputId": "314bde46-9550-421a-8d0d-0d8265e2c1a8"
   },
   "outputs": [],
   "source": [
    "df_pc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1734097280088,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "LvvpG6Mn1yjR",
    "outputId": "54ab2614-2b4e-438d-cb1f-646d4f81a1d7"
   },
   "outputs": [],
   "source": [
    "df_pc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfXMZYb2Podz",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3. Transformation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPXkPZLdu536"
   },
   "source": [
    "## Supprimer Date Cohérence I2M2\n",
    "\n",
    "Nous avons décidé de supprimer les données de 2005 à 2007 pour avoir une cohérence avec les données hydrobiologique car cette plage de temps n'est pas présente dans ses donnéees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "executionInfo": {
     "elapsed": 6900,
     "status": "ok",
     "timestamp": 1734099747590,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "jnyopRVS1yjS",
    "outputId": "739317a6-d97d-41a8-f515-5457c0c9ee2c"
   },
   "outputs": [],
   "source": [
    "df_pc['DatePrel'].value_counts().sort_index()\n",
    "df_pc = df_pc[df_pc['DatePrel'] > '2006-12-31']\n",
    "df_pc['DatePrel'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDLqu7fqP8AQ"
   },
   "source": [
    "## Ajout des Lables pour répartir données par saison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60GdIvXPwja7"
   },
   "source": [
    "Nous avons décidé d'ajouter une colonne Saison et LbSaison. Ce choix se justifie par la volonté de mieux suivre les variations saisonnières et les effets qui prennent du temps à apparaître. Cela nous permettra de comparer des périodes similaires et d'eviter les erreurs en cas d'événements exceptionnels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1734097283072,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "viulUBw-1yjS"
   },
   "outputs": [],
   "source": [
    "## Regroupe les données par saison\n",
    "df_pc['Saison'] = df_pc['DatePrel'].dt.month.map({\n",
    "    12: 1, 1: 1, 2: 1,      # Hiver\n",
    "    3: 2, 4: 2, 5: 2,       # Printemps\n",
    "    6: 3, 7: 3, 8: 3,       # Été\n",
    "    9: 4, 10: 4, 11: 4      # Automne\n",
    "})\n",
    "\n",
    "# Ajouter une colonne \"LbSaison\" pour le libellé de la saison\n",
    "df_pc['LbSaison'] = df_pc['DatePrel'].dt.month.map({\n",
    "    12: 'Hiver', 1: 'Hiver', 2: 'Hiver',        # Hiver\n",
    "    3: 'Printemps', 4: 'Printemps', 5: 'Printemps',  # Printemps\n",
    "    6: 'Ete', 7: 'Ete', 8: 'Ete',              # Été\n",
    "    9: 'Automne', 10: 'Automne', 11: 'Automne'  # Automne\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1734097283514,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "Wo9Bryuk1yjT",
    "outputId": "63e13402-555e-43af-9cc7-93e6fdf8a1cf"
   },
   "outputs": [],
   "source": [
    "# Vérification du résultat\n",
    "print(df_pc[['DatePrel', 'Saison', 'LbSaison']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhgQuSFVBN3h"
   },
   "source": [
    "## Visualisation de la quantité de donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "executionInfo": {
     "elapsed": 2058,
     "status": "ok",
     "timestamp": 1734097285547,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "DvQWN7_b-1jm",
    "outputId": "940aa1c1-2d56-4098-d4ac-7592e4694bcb"
   },
   "outputs": [],
   "source": [
    "# Extraire l'année et le mois de la colonne 'DatePrel'\n",
    "df_pc['Year'] = pd.to_datetime(df_pc['DatePrel']).dt.year\n",
    "df_pc['Month'] = pd.to_datetime(df_pc['DatePrel']).dt.month\n",
    "\n",
    "# Calculer la somme des données pour chaque année\n",
    "compte_par_annee = df_pc.groupby('Year').size()\n",
    "\n",
    "# Tracer l'histogramme\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(compte_par_annee.index, compte_par_annee.values, color='skyblue')\n",
    "\n",
    "# Ajouter des éléments au graphique\n",
    "plt.title('Quantité totale de données par année', fontsize=14)\n",
    "plt.xlabel('Année', fontsize=12)\n",
    "plt.ylabel('Quantité totale de données', fontsize=12)\n",
    "plt.xticks(compte_par_annee.index, rotation=45, fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zX_8irUc1yjV"
   },
   "source": [
    "## Afficher les stations sur une carte pour séparer en hydroecoregions\n",
    "\n",
    "Permet de visuellement se representer les stations dans chaque hydroecoregions et de modifier le dataset pour y ajouter le code et le nom de chaque hydroeco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "executionInfo": {
     "elapsed": 3855,
     "status": "ok",
     "timestamp": 1734097289380,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "wkgDdqAd1yjV",
    "outputId": "eda983ad-1daf-46b8-d0a7-8a4d7393bdc4"
   },
   "outputs": [],
   "source": [
    "# Définir la projection Lambert 93\n",
    "crs_lambert = 'PROJCS[\"RGF_1993_Lambert_93\",GEOGCS[\"GCS_RGF_1993\",DATUM[\"D_RGF_1993\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Lambert_Conformal_Conic\"],PARAMETER[\"False_Easting\",700000.0],PARAMETER[\"False_Northing\",6600000.0],PARAMETER[\"Central_Meridian\",3.0],PARAMETER[\"Standard_Parallel_1\",49.0],PARAMETER[\"Standard_Parallel_2\",44.0],PARAMETER[\"Latitude_Of_Origin\",46.5],UNIT[\"Meter\",1.0]]'\n",
    "\n",
    "# Colonnes des coordonnées X et Y\n",
    "x_col = 'CoordXStationMesureEauxSurface'\n",
    "y_col = 'CoordYStationMesureEauxSurface'\n",
    "\n",
    "\n",
    "gdf_stations = gpd.GeoDataFrame(\n",
    "    df_stations,\n",
    "    crs=crs_lambert,\n",
    "    geometry=gpd.GeoSeries(df_stations.apply(lambda row: geom.Point(row[x_col], row[y_col]), axis=1))\n",
    ")\n",
    "\n",
    "# her = gpd.read_file(root_path+\"Hydroecoregion1-shp/Hydroecoregion1.shp\")\n",
    "her = gpd.read_file(\"./donnees/Hydroecoregions/Hydroecoregion1.shp\")\n",
    "\n",
    "shp_hydroecoregions = her.to_crs(crs_lambert)\n",
    "\n",
    "station_her = gpd.sjoin(gdf_stations, shp_hydroecoregions, predicate='within').to_crs(crs_lambert)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "shp_hydroecoregions.plot(ax=ax, color='grey', edgecolor='black', alpha=0.1, label='Hydroécorégions')\n",
    "\n",
    "#station_her.plot(ax=ax, marker='o', color='#ca4553', markersize=0.2, label='Stations de mesure')\n",
    "station_her.plot(column='NomHER1',markersize=1, cmap='twilight', legend=True, ax=ax)\n",
    "\n",
    "#station_her.head()\n",
    "\n",
    "# Ajouter une légende et un titre\n",
    "plt.title(\"Carte des stations de mesure en France avec hydroécorégions et frontières\")\n",
    "plt.legend()\n",
    "\n",
    "# Afficher la carte\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydEWJpaVbKCo",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4. Début analyse PC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozztp9U_1yjX",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Donnée avec parametres selectionnés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfIB91NR29dv"
   },
   "source": [
    "Nous avons décider de faire une pré séléection des parametres que nous avons estimé important de garder. Pour estimer les paramètres, nous sous somme sbasés sur les paramètres en lien avec la physico chiique de l'eau et les éléments indicatif du prélèvement et ceux qui potentiellement ont un impact sur la valeur des parametres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "executionInfo": {
     "elapsed": 3001,
     "status": "ok",
     "timestamp": 1734097292359,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "mLG0IuejV4OJ",
    "outputId": "ef887b46-d038-4263-a7ae-99b2e9a5a865"
   },
   "outputs": [],
   "source": [
    "new_data = df_pc[['CdStationMesureEauxSurface', 'CdSupport', 'DatePrel',\n",
    "                  'CdParametre', 'RsAna', 'ProfondeurPrel',\n",
    "                  'LdAna', 'LqAna', 'LsAna', 'LbSaison', 'CdPrelevement']]\n",
    "\n",
    "new_data['Year'] = pd.to_datetime(new_data['DatePrel']).dt.year\n",
    "compte_par_annee = new_data.groupby(['Year']).count()\n",
    "\n",
    "# Calculer le pourcentage pour chaque paramètre par année\n",
    "compte_par_annee_percent = compte_par_annee.div(compte_par_annee.sum(axis=1), axis=0) * 100\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for param in compte_par_annee_percent.columns:\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=compte_par_annee_percent.index,\n",
    "        y=compte_par_annee_percent[param],\n",
    "        name=param\n",
    "    ))\n",
    "\n",
    "# Mise en forme du graphique\n",
    "fig.update_layout(\n",
    "    barmode='stack',\n",
    "    title=\"Pourcentage de données par année et paramètre\",\n",
    "    xaxis_title=\"Année\",\n",
    "    yaxis_title=\"Pourcentage de données (%)\",\n",
    "    xaxis_tickmode='array',\n",
    "    xaxis_tickvals=compte_par_annee_percent.index,\n",
    "    xaxis_tickangle=45\n",
    ")\n",
    "\n",
    "# Affichage du graphique\n",
    "fig.show(renderer='browser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5426,
     "status": "ok",
     "timestamp": 1734097297766,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "qn3k-Jiq1yjX",
    "outputId": "b2ee0462-d797-4649-e241-4af0d2b83786"
   },
   "outputs": [],
   "source": [
    "new_data = df_pc[['CdStationMesureEauxSurface', 'CdSupport', 'DatePrel',\n",
    "                   'CdParametre', 'RsAna','ProfondeurPrel',\n",
    "                   'LdAna', 'LqAna', 'LsAna', 'LbSaison', 'CdPrelevement']]\n",
    "\n",
    "new_data['Year'] = pd.to_datetime(new_data['DatePrel']).dt.year\n",
    "compte_par_annee = new_data.groupby('Year').count()\n",
    "\n",
    "# Tracer un graphique pour chaque paramètre\n",
    "for param in compte_par_annee.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(compte_par_annee.index, compte_par_annee[param], color='skyblue')\n",
    "    plt.title(f'Nombre de données par année pour {param}')\n",
    "    plt.xlabel('Année')\n",
    "    plt.ylabel('Nombre de données')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psDsxVxa1yjY"
   },
   "source": [
    "Une fois qu'on a vu la répartition des données, j'ai fais un \"tri\". J'ai retiré les paramètres qui ne sont pas nombreux et mal répartis sur les années. Par la suite, jee regarde le nombre de valeur nul pour chaque colonne que j'ai gardé pour voir l'impact des valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 10042,
     "status": "ok",
     "timestamp": 1734097307792,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "xwuZLOwr1yjY",
    "outputId": "74d16ccc-b530-4fcf-c302-754817c27bff"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Sélectionner les colonnes nécessaires\n",
    "new_data = df_pc[['CdStationMesureEauxSurface', 'CdSupport', 'DatePrel',\n",
    "                  'CdParametre', 'LbSaison', 'CdPrelevement', 'RsAna']]\n",
    "\n",
    "# Extraire l'année de la colonne 'DatePrel'\n",
    "new_data['Year'] = pd.to_datetime(new_data['DatePrel']).dt.year\n",
    "\n",
    "# Définir le nombre de colonnes pour le layout des graphiques\n",
    "ncols = 3  # Nombre de colonnes de subplots (ajusté pour mieux utiliser l'espace)\n",
    "nrows = (len(new_data.columns) - 1) // ncols + 1  # Calculer le nombre de lignes nécessaires\n",
    "\n",
    "# Créer la figure et les subplots avec un format paysage\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(18, 7 * nrows))  # Augmenter la largeur pour le format paysage\n",
    "axes = axes.flatten()  # Aplatir l'array pour accéder facilement aux axes\n",
    "\n",
    "# Tracer les données pour chaque paramètre\n",
    "for idx, param in enumerate(new_data.columns[:-1]):\n",
    "    # Compter les valeurs non nulles et nulles par année pour chaque paramètre\n",
    "    non_null_count = new_data.groupby('Year')[param].apply(lambda x: x.notnull().sum())\n",
    "    null_count = new_data.groupby('Year')[param].apply(lambda x: x.isnull().sum())\n",
    "\n",
    "    # Tracer les données nulles et non nulles\n",
    "    axes[idx].bar(non_null_count.index - 0.2, non_null_count, width=0.4, label='Non Nulles', color='skyblue')\n",
    "    axes[idx].bar(null_count.index + 0.2, null_count, width=0.4, label='Nulles', color='red')\n",
    "\n",
    "    # # Ajouter les annotations sur chaque barre\n",
    "    # for i, val in enumerate(non_null_count):\n",
    "    #     axes[idx].text(non_null_count.index[i] - 0.2, val, int(val), ha='center', va='bottom')\n",
    "    # for i, val in enumerate(null_count):\n",
    "    #     axes[idx].text(null_count.index[i] + 0.2, val, int(val), ha='center', va='bottom')\n",
    "\n",
    "    # Ajouter les titres et légendes\n",
    "    axes[idx].set_title(f'Quantité de données nulles et non nulles par année pour {param}')\n",
    "    axes[idx].set_xlabel('Année')\n",
    "    axes[idx].set_ylabel('Nombre de données')\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "    axes[idx].legend()\n",
    "\n",
    "# Ajuster les espacements pour ne pas que les graphiques se chevauchent\n",
    "plt.tight_layout()\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wx-u2T9s1yjY"
   },
   "source": [
    "Valeur nulle insignifiante pour RsAna donc à supprimer\n",
    "\n",
    "Pour ce qui est des années à garder je pense que de garder les années de 2015 à 2018 est intéressant car celles-ci ont le plus de données à analyser\n",
    "\n",
    "Nous avons garder les paramètres:\n",
    "- '**CdStationMesureEauxSurface**': Identifiant de la station de mesure dans le référentiel national Sandre. Ce champ permet d'effectuer une jointure avec les fichiers stations et analyses\n",
    "- '**CdSupport**': Un support désigne un COMPOSANT DU MILIEU SUR LEQUEL PORTE L’INVESTIGATION, faisant généralement l'objet de prélèvements en vue d'analyses ultérieures, afin d’évaluer sa qualité et celle du milieu. Necessaire pour l'analyse\n",
    "- '**DatePrel**': La date du début du prélèvement physico-chimique est la date à laquelle commence le prélèvement. La date est donnée au jour pres\n",
    "- '**CdParametre**': Un paramètre est une propriété du milieu ou d'une partie du milieu qui contribue à en apprécier les caractéristiques et/ou la qualité et/ou l'aptitude à des usages\n",
    "- '**LbSaison**': Nom de la saison\n",
    "- '**CdPrelevement**' : La référence du prélèvement physico-chimique et biologique chez le producteur est la référence qu'affecte le producteur de données au prélèvement à des fins de gestion et de correspondance notamment pour la facturation des prestations.\n",
    "- '**RsAna**':   Le résultat de l'analyse physico-chimique est soit la valeur du résultat du paramètre quantitatif, soit le code de la valeur possible du paramètre qualitatif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIuUs2x0PDT_",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Nettoyer données\n",
    "\n",
    "Au vue des graphiques ci-dessus, nous avons pu constater la répartition des données était importante entre 2015 et 2018. Nous nous sommes donc concentrés sur cet intervalle pour faire nos analyses.\n",
    "\n",
    "Une fois que l'intervalle choisi et les paramètres trouvés, je supprime les valeurs NULLE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 613
    },
    "executionInfo": {
     "elapsed": 666,
     "status": "ok",
     "timestamp": 1734097308434,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "w-crsAqqPbNy",
    "outputId": "d741cf08-1541-457e-93f0-c0756d1be967"
   },
   "outputs": [],
   "source": [
    "#Filtrer les données de 2015 à 2018\n",
    "new_data_filtered = new_data[(new_data['DatePrel'].dt.year >= 2015) & (new_data['DatePrel'].dt.year <= 2018)]\n",
    "new_data_filtered.shape\n",
    "\n",
    "\n",
    "#Avant supprimer nombre donnée\n",
    "print(\"Avant suppression des valeurs nulles :\", new_data_filtered.shape)\n",
    "# Supprimer les lignes avec des valeurs nulles\n",
    "new_data_filtered_cleaned = new_data_filtered.dropna()\n",
    "#Apres supprimer nombre donnée\n",
    "print(\"Après suppression des valeurs nulles :\", new_data_filtered_cleaned.shape)\n",
    "new_data_filtered_cleaned.groupby('CdStationMesureEauxSurface').size()\n",
    "\n",
    "# df = px.data.tips()\n",
    "# fig = px.box(new_data_filtered_cleaned.groupby('CdStationMesureEauxSurface').size().sort_values(ascending=False))\n",
    "# fig.show()\n",
    "# station_counts = new_data_filtered_cleaned.groupby('CdStationMesureEauxSurface').size().sort_values(ascending=False)\n",
    "# station_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIsa1_ouRl4f",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Supprimer les doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1382,
     "status": "ok",
     "timestamp": 1734097309800,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "Wj2b5AVLR0zl",
    "outputId": "e3873439-4347-4cf2-84af-7a9a9ee21f06"
   },
   "outputs": [],
   "source": [
    "duplicates = new_data_filtered_cleaned[new_data_filtered_cleaned.duplicated(keep=False)]\n",
    "\n",
    "# Afficher les doublons\n",
    "print(f\"Nombre de doublons trouvés : {duplicates.shape[0]}\")\n",
    "print(duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1235,
     "status": "ok",
     "timestamp": 1734097311015,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "tKWyfs8yWJKG",
    "outputId": "69e5f902-76b6-45e0-f1d6-4c0d16d4f3a7"
   },
   "outputs": [],
   "source": [
    "new_data_filtered_cleaned.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1734097311015,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "ttT8SGIjG_rT",
    "outputId": "93a44bd4-ea03-40fd-9c2f-fc8ae34dd526"
   },
   "outputs": [],
   "source": [
    "new_data_filtered_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZN74nwQ2ShG2",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Répartiton des saisons sur l'année"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1872,
     "status": "ok",
     "timestamp": 1734097312869,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "-kyOJ4HySwVK",
    "outputId": "e57321ad-c5d3-4282-ee2f-d38f1c31af9b"
   },
   "outputs": [],
   "source": [
    "new_data_filtered_cleaned['DatePrel'] = pd.to_datetime(new_data_filtered_cleaned['DatePrel'])\n",
    "new_data_filtered_cleaned['Year'] = new_data_filtered_cleaned['DatePrel'].dt.year\n",
    "\n",
    "# Grouper par année et saison, et compter les occurrences\n",
    "data_by_year_season = new_data_filtered_cleaned.groupby(['Year', 'LbSaison']).size().unstack(fill_value=0)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = data_by_year_season.plot(kind='bar', stacked=True, figsize=(14, 8), colormap='viridis')\n",
    "\n",
    "# Ajouter des annotations pour les quantités\n",
    "for i in range(data_by_year_season.shape[0]):  # Parcourir chaque année (chaque barre)\n",
    "    cumulative_height = 0  # Hauteur cumulative pour positionner les annotations\n",
    "    for j, season in enumerate(data_by_year_season.columns):  # Parcourir chaque saison\n",
    "        value = data_by_year_season.iloc[i, j]\n",
    "        if value > 0:  # Si la valeur est non nulle\n",
    "            ax.text(i, cumulative_height + value / 2,  # Position : au centre du segment\n",
    "                    str(value), ha='center', va='center', fontsize=10, color='white')\n",
    "            cumulative_height += value  # Mettre à jour la hauteur cumulative\n",
    "\n",
    "\n",
    "plt.title(\"Répartition des données par saison pour chaque année\", fontsize=16)\n",
    "plt.xlabel(\"Année\", fontsize=14)\n",
    "plt.ylabel(\"Nombre de données\", fontsize=14)\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "plt.legend(title=\"Saison\", fontsize=12, loc='upper left')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAvrt5-kat4A"
   },
   "source": [
    "On peut voir que la quantité de donnée est bien répartis entre les saisons de chaque année."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8qaNOEVTuA7",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Répartition par mois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "executionInfo": {
     "elapsed": 862,
     "status": "ok",
     "timestamp": 1734097313717,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "hiR2HJonTyKg",
    "outputId": "c58d982a-33a6-4e50-eeba-53630673929f"
   },
   "outputs": [],
   "source": [
    "# Ajouter des colonnes 'year' et 'month' pour le regroupement\n",
    "new_data_filtered_cleaned['Year'] = new_data_filtered_cleaned['DatePrel'].dt.year\n",
    "new_data_filtered_cleaned['Month'] = new_data_filtered_cleaned['DatePrel'].dt.month\n",
    "\n",
    "# Calculer la quantité de données par mois pour chaque année\n",
    "monthly_data = new_data_filtered_cleaned.groupby(['Year', 'Month']).size().unstack(fill_value=0)\n",
    "\n",
    "# Tracer le graphique\n",
    "monthly_data.plot(kind='bar', stacked=False, figsize=(12, 6))\n",
    "plt.title(\"Quantité de données par mois de chaque année\")\n",
    "plt.xlabel(\"Année - Mois\")\n",
    "plt.ylabel(\"Nombre de données\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Mois\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E98cabrlIPPq"
   },
   "source": [
    "**A voir si on choisit des mois specifique**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XbMMVIGarez"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIITAuxNT-fI",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Verification maintenant des répartition dans les stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqvPhKS0H4Eg"
   },
   "source": [
    "## Répartion sur boxplot des stations pour faire le choix des stations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJp7waiISLyz"
   },
   "source": [
    "AVANT ENLEVER VALEUR ABERRANTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1378,
     "status": "ok",
     "timestamp": 1734097315072,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "iUcBkjB9H7jp",
    "outputId": "3c6e2c27-646c-427c-969e-9bc687b5bd66"
   },
   "outputs": [],
   "source": [
    "new_data_filtered_cleaned['Month'] = pd.to_datetime(new_data_filtered_cleaned['DatePrel']).dt.month\n",
    "new_data_filtered_cleaned['Year'] = pd.to_datetime(new_data_filtered_cleaned['DatePrel']).dt.year\n",
    "\n",
    "new_data_filtered_cleaned = new_data_filtered_cleaned.dropna(subset=['RsAna'])\n",
    "preprocess_df = new_data_filtered_cleaned.drop(columns=['CdPrelevement', 'DatePrel','CdSupport','CdParametre', 'LbSaison'])\n",
    "print(preprocess_df)\n",
    "\n",
    "df = px.data.tips()\n",
    "fig = px.box(preprocess_df.groupby('CdStationMesureEauxSurface').size().sort_values(ascending=False))\n",
    "fig.show(renderer='browser')\n",
    "station_counts = preprocess_df.groupby('CdStationMesureEauxSurface').size().sort_values(ascending=False)\n",
    "station_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArKHU0dnSQg7"
   },
   "source": [
    "APRES AVOIR ENLEVER VALEUR ABERRANTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1734097315664,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "4IAw2ibqSU0l",
    "outputId": "e025a785-211c-46a5-e282-ffdb6fba7819"
   },
   "outputs": [],
   "source": [
    "new_data_filtered_cleaned['Month'] = pd.to_datetime(new_data_filtered_cleaned['DatePrel']).dt.month\n",
    "new_data_filtered_cleaned['Year'] = pd.to_datetime(new_data_filtered_cleaned['DatePrel']).dt.year\n",
    "\n",
    "\n",
    "new_data_filtered_cleaned = new_data_filtered_cleaned.dropna(subset=['RsAna'])\n",
    "preprocess_df = new_data_filtered_cleaned.drop(columns=['CdPrelevement', 'DatePrel','CdSupport','CdParametre', 'LbSaison'])\n",
    "station_counts = preprocess_df.groupby('CdStationMesureEauxSurface').size()\n",
    "\n",
    "# Étape 5 : Calculer les valeurs aberrantes pour le boxplot\n",
    "Q1 = station_counts.quantile(0.25)\n",
    "Q3 = station_counts.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Définir les bornes pour les valeurs aberrantes\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filtrer les stations dans la plage sans valeurs aberrantes\n",
    "stations_filtered = station_counts[(station_counts >= lower_bound) & (station_counts <= upper_bound)].index\n",
    "preprocess_df_filtered = preprocess_df[preprocess_df['CdStationMesureEauxSurface'].isin(stations_filtered)]\n",
    "\n",
    "# Afficher le résultat après filtrage\n",
    "print(preprocess_df_filtered)\n",
    "\n",
    "# Afficher le boxplot sans valeurs aberrantes\n",
    "fig = px.box(preprocess_df_filtered.groupby('CdStationMesureEauxSurface').size().sort_values(ascending=False))\n",
    "fig.show(renderer='browser')\n",
    "\n",
    "station_counts = preprocess_df_filtered.groupby('CdStationMesureEauxSurface').size().sort_values(ascending=False)\n",
    "station_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neL35TKgeAK0"
   },
   "source": [
    "## Station au dela de 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "executionInfo": {
     "elapsed": 727,
     "status": "ok",
     "timestamp": 1734097316376,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "T8ZrbaA4ZK18",
    "outputId": "c0841482-8e0c-46c3-9fb0-15a078ae92cc"
   },
   "outputs": [],
   "source": [
    "#prs les valeurs composé dana sle boxplot\n",
    "preprocess_df_filtered = preprocess_df_filtered.groupby('CdStationMesureEauxSurface').filter(lambda g: len(g) > 56 and len(g) <= 462)\n",
    "\n",
    "station_count_non_null = preprocess_df_filtered.groupby('CdStationMesureEauxSurface').size().sort_values(ascending=False)\n",
    "station_count_non_null\n",
    "\n",
    "# station_count_non_null = station_count_non_null[station_count_non_null > 56].sort_values(ascending=False)\n",
    "# station_count_non_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1734097316376,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "FwD2zB-xVJyD"
   },
   "outputs": [],
   "source": [
    "## TO DO\n",
    "# Supprimer les stations qui sont egale à 0\n",
    "station_count_non_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhcF6gskgWyS"
   },
   "source": [
    "Maintenant faut voir les valeurs mesure dans chaque station pour voir lesquels prendre c'est bcp plus simple pour faire un tri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vLKUH8TVQW6",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Verification des CdParametre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEZjYuR4ZFw5"
   },
   "source": [
    "## Répartiton des parametre Physico-chimique\n",
    "\n",
    "Nous visualisons dans un premier temps, la maniere dont les parametres sont répartis en fonction des saisons pour une premiere approche. Cette visualisation nous permettra d'avoir une idée sur l'impact saisonnier sur les parametres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7vqq3eTR-Pv"
   },
   "source": [
    "## Graphique répartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5124,
     "status": "ok",
     "timestamp": 1734097321486,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "6DiTa4bER7AT",
    "outputId": "d79b9e3f-749d-490b-a393-527558757e72"
   },
   "outputs": [],
   "source": [
    "new_data_filtered_cleaned['DatePrel'] = pd.to_datetime(new_data['DatePrel'])\n",
    "new_data_filtered_cleaned['Year'] = new_data_filtered_cleaned['DatePrel'].dt.year\n",
    "new_data_filtered_cleaned['Month'] = new_data_filtered_cleaned['DatePrel'].dt.month\n",
    "\n",
    "\n",
    "years = new_data_filtered_cleaned['Year'].unique()\n",
    "\n",
    "# Nombre de lignes et de colonnes pour la grille de sous-graphes\n",
    "n_rows = (len(years) + 1) // 2  # 2 graphiques par ligne\n",
    "n_cols = 2\n",
    "\n",
    "# Créer une figure et des sous-graphes\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 5))\n",
    "axes = axes.flatten()  # Aplatir le tableau de sous-graphes pour un accès facile\n",
    "\n",
    "# Boucle à travers chaque année pour créer les graphiques\n",
    "for idx, year in enumerate(years):\n",
    "    # Filtrer les données pour l'année courante\n",
    "    data_year = new_data_filtered_cleaned[new_data_filtered_cleaned['Year'] == year]\n",
    "\n",
    "    # Compter les occurrences par saison et paramètre\n",
    "    repartition = data_year.groupby(['LbSaison', 'CdParametre']).size().unstack(fill_value=0)\n",
    "\n",
    "    # Tracer le graphique dans le sous-graphe correspondant\n",
    "    ax = axes[idx]\n",
    "    repartition.plot(kind='bar', stacked=True, ax=ax, colormap='viridis')\n",
    "\n",
    "    # Ajouter les annotations sur chaque portion du graphique\n",
    "    for i in range(repartition.shape[0]):  # Pour chaque saison\n",
    "        cumulative_height = 0  # Initialiser la hauteur cumulative\n",
    "        for j in range(repartition.shape[1]):  # Pour chaque paramètre\n",
    "            height = repartition.iloc[i, j]  # Hauteur de la barre courante\n",
    "            if height > 0:  # Vérifier si la hauteur est positive\n",
    "                ax.annotate(f'{height}',\n",
    "                            (i, cumulative_height + height / 2),  # Position ajustée au centre de la barre\n",
    "                            ha='center', va='center', fontsize=10, color='white')\n",
    "            cumulative_height += height  # Mettre à jour la hauteur cumulative\n",
    "\n",
    "    # Titre et labels\n",
    "    ax.set_title(f'Répartition des données CdParametre en fonction des Saisons pour l\\'année {year}')\n",
    "    ax.set_xlabel('Saison')\n",
    "    ax.set_ylabel('Nombre d\\'occurrences')\n",
    "    ax.set_xticks(range(repartition.shape[0]))\n",
    "    ax.set_xticklabels(repartition.index, rotation=0)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXSBc2s7asZS"
   },
   "source": [
    "\n",
    "Ce graphique nous permet de sélectionner un paramètre afin d'observer son impact physico-chimique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGxp2EHa1yjb"
   },
   "source": [
    "### Données par saison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1734097321487,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "8zycHA2PbW54",
    "outputId": "80aeae9b-67d0-40b5-d84c-14eff0cfe601"
   },
   "outputs": [],
   "source": [
    "parametre_count = new_data_filtered_cleaned.groupby('CdParametre').size().sort_values(ascending=True)\n",
    "parametre_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "executionInfo": {
     "elapsed": 1097,
     "status": "ok",
     "timestamp": 1734097322564,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "S48mpCuWI3hG",
    "outputId": "75c43316-0d17-43a2-c2e8-c509b8776d6f"
   },
   "outputs": [],
   "source": [
    "nom=df_pc[['LbLongParamètre','CdParametre']].drop_duplicates().reset_index(drop=True)\n",
    "nom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JFM5-i53Qnb"
   },
   "source": [
    "Je dois verifier:\n",
    "- Si les paramètres ont le même impact sur l'eau\n",
    "- En fonction de la quantité: voir si pertinent de les garder\n",
    "(Dans mes notes)\n",
    "\n",
    "Pour les regrouper:\n",
    "- **Matière organique et oxydable:** 1312, 1313, 1335, 1311, 1841\n",
    "- **Particules en suspension:** 1295, 1305\n",
    "- **Matière azotées:** 1319,1339\n",
    "- **Matière phosporées:** 1350,1433\n",
    "- **Acidification:** 1302\n",
    "- **Pesticides sur eau brutes:** 1177\n",
    "- **Nitrates:** 1340\n",
    "- **Minéralisation:** 1303\n",
    "- **Temperature:** 1301\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hJ04jvcKd-S"
   },
   "source": [
    "## Quantité de parametre par station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 867,
     "status": "ok",
     "timestamp": 1734097322564,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "8PvpnZkkk9sJ",
    "outputId": "17c6c011-e94b-4b67-a1ed-767015677c28"
   },
   "outputs": [],
   "source": [
    "# Calculer la quantité de CdParametre par station\n",
    "quantite_par_station = new_data_filtered_cleaned.groupby('CdStationMesureEauxSurface')['CdParametre'].count()\n",
    "\n",
    "# # Afficher les résultats\n",
    "# print(\"Quantité de CdParametre par station :\")\n",
    "# print(quantite_par_station)\n",
    "\n",
    "print(len(quantite_par_station))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 848,
     "status": "ok",
     "timestamp": 1734097322564,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "blAJ_URrKpJ2",
    "outputId": "4bdf3352-0f55-4c75-a5db-f2e8343db423"
   },
   "outputs": [],
   "source": [
    "# Calculer la quantité de CdParametre par station\n",
    "quantite_par_station = new_data_filtered_cleaned.groupby('CdStationMesureEauxSurface')['CdParametre'].count()\n",
    "\n",
    "# Filtrer les stations avec une quantité supérieure à 0\n",
    "stations_non_vides = quantite_par_station[quantite_par_station > 0]\n",
    "\n",
    "# Afficher les stations correspondantes\n",
    "print(\"Stations avec une quantité de CdParametre supérieure à 0 :\")\n",
    "print(stations_non_vides)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 830,
     "status": "ok",
     "timestamp": 1734097322565,
     "user": {
      "displayName": "jaidane chaima",
      "userId": "17848125768293497184"
     },
     "user_tz": -60
    },
    "id": "jT-hSMF1LDK9",
    "outputId": "80f289a7-9fa6-448e-d799-aa95ab6d3db9"
   },
   "outputs": [],
   "source": [
    "stations_ids = stations_non_vides.index.tolist()\n",
    "#print(\"Liste des stations avec des données disponibles :\")\n",
    "#print(stations_ids)\n",
    "\n",
    "nombre=len(stations_ids)\n",
    "print(nombre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_vides = quantite_par_station[quantite_par_station == 0]\n",
    "dfstations_vides = stations_vides.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Tendance et analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importer les donnees de l'hyrdoecoregion 20 avec la qualite en fonction des Clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour les differents datasets selectionnes\n",
    "\n",
    "Importation des valeurs et creation des dataset resultants\n",
    "(HER 9/11/20/...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour recuperer uniquement les nitrates \n",
    "nitrate_new_data_filtered_cleaned = new_data_filtered_cleaned[new_data_filtered_cleaned['CdParametre'] == '1340']\n",
    "oxdissous_new_data_filtered_cleaned = new_data_filtered_cleaned[new_data_filtered_cleaned['CdParametre'] == '1311']\n",
    "dbo5_new_data_filtered_cleaned = new_data_filtered_cleaned[new_data_filtered_cleaned['CdParametre'] == '1313']\n",
    "phosphore_new_data_filtered_cleaned = new_data_filtered_cleaned[new_data_filtered_cleaned['CdParametre'] == '1350']\n",
    "\n",
    "# Dictionnaire des seuils pour chaque HER (uniquement pour le cas general pour le moment)\n",
    "her_thresholds = {\n",
    "    2: [0.7078, 0.457, 0.3047, 0.1523],\n",
    "    7: [0.6916, 0.4362, 0.2908, 0.1454],\n",
    "    11: [0.7003, 0.5252, 0.3501, 0.1751],\n",
    "    13: [0.7003, 0.5252, 0.3501, 0.1751],\n",
    "    15: [0.7003, 0.5164, 0.3443, 0.1721],\n",
    "    19: [0.7003, 0.5252, 0.3501, 0.1751],\n",
    "    20: [0.7003, 0.5164, 0.3443, 0.1721],\n",
    "    9: [0.7003, 0.5164, 0.3443, 0.1721]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour le nitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dictionnaire pour stocker les DataFrames par valeur de HER\n",
    "results_by_her = {}\n",
    "\n",
    "# Parcourir tous les seuils dans her_thresholds\n",
    "for dftorec in her_thresholds:\n",
    "    data_nitrate = []  # Stocker les résultats pour les nitrates\n",
    "    data_oxdissous = []  # Stocker les résultats pour l'oxygène dissous\n",
    "    data_dbo5 = []  # Stocker les résultats pour l'oxygène dissous\n",
    "    data_phosphore = []  # Stocker les résultats pour l'oxygène dissous\n",
    "\n",
    "    # Charger le fichier CSV correspondant\n",
    "    csv_path = f'./donnees/resultats_releves_H{dftorec}_station_bonne-mauvaise.csv'\n",
    "    df_hb_resultats_clustering = pd.read_csv(csv_path)\n",
    "\n",
    "    # Conversion de CdStationMesureEauxSurface en string et harmonisation des formats\n",
    "    for df in [nitrate_new_data_filtered_cleaned, oxdissous_new_data_filtered_cleaned, dbo5_new_data_filtered_cleaned, phosphore_new_data_filtered_cleaned]:\n",
    "        df[\"CdStationMesureEauxSurface\"] = df[\"CdStationMesureEauxSurface\"].astype(str)\n",
    "\n",
    "    df_hb_resultats_clustering[\"CdStationMesureEauxSurface\"] = (\n",
    "        df_hb_resultats_clustering[\"CdStationMesureEauxSurface\"]\n",
    "        .astype(str)\n",
    "        .str.zfill(8)  # Ajouter des zéros devant si nécessaire\n",
    "    )\n",
    "\n",
    "    # Obtenir les stations uniques pour le seuil en cours\n",
    "    stations_pre_dataset = df_hb_resultats_clustering[\"CdStationMesureEauxSurface\"].unique()\n",
    "\n",
    "    # Filtrer les données pour ces stations\n",
    "    filtered_df_hb_nitrate = nitrate_new_data_filtered_cleaned[\n",
    "        nitrate_new_data_filtered_cleaned[\"CdStationMesureEauxSurface\"].isin(stations_pre_dataset)\n",
    "    ]\n",
    "    filtered_df_hb_oxdissous = oxdissous_new_data_filtered_cleaned[\n",
    "        oxdissous_new_data_filtered_cleaned[\"CdStationMesureEauxSurface\"].isin(stations_pre_dataset)\n",
    "    ]\n",
    "    filtered_df_hb_dbo5 = dbo5_new_data_filtered_cleaned[\n",
    "        dbo5_new_data_filtered_cleaned[\"CdStationMesureEauxSurface\"].isin(stations_pre_dataset)\n",
    "    ]\n",
    "    filtered_df_hb_phosphore = phosphore_new_data_filtered_cleaned[\n",
    "        phosphore_new_data_filtered_cleaned[\"CdStationMesureEauxSurface\"].isin(stations_pre_dataset)\n",
    "    ]\n",
    "\n",
    "    # Fonction pour calculer les médianes et résultats\n",
    "    def process_data(filtered_data, param_name, data_storage):\n",
    "        for season in filtered_data['LbSaison'].unique():\n",
    "            # Filtrer les données pour la saison actuelle\n",
    "            filtered_season_data = filtered_data[filtered_data['LbSaison'] == season]\n",
    "\n",
    "            # Assurer que les données sont en format datetime et triées par date\n",
    "            filtered_season_data[\"DatePrel\"] = pd.to_datetime(filtered_season_data[\"DatePrel\"])\n",
    "            filtered_season_data = filtered_season_data.sort_values(by=[\"DatePrel\"])\n",
    "\n",
    "            # Calcul de la médiane pour chaque station\n",
    "            for station, group in filtered_season_data.groupby(\"CdStationMesureEauxSurface\"):\n",
    "                # Calcul de la médiane des valeurs RsAna\n",
    "                median_value = group[\"RsAna\"].median()\n",
    "\n",
    "                # Récupérer la qualité pour l'affichage (la qualité est toujours la même pour la station)\n",
    "                tmp = df_hb_resultats_clustering[\n",
    "                    df_hb_resultats_clustering['CdStationMesureEauxSurface'] == station\n",
    "                ].iloc[0]\n",
    "\n",
    "                # Ajouter les résultats sous forme de ligne dans la liste de données\n",
    "                data_storage.append({\n",
    "                    \"CdStationMesureEauxSurface\": station,\n",
    "                    \"Saison\": season,\n",
    "                    f\"median{param_name}\": median_value,\n",
    "                    \"measureFromHB\": tmp['Cluster']\n",
    "                })\n",
    "\n",
    "    # Traiter les données pour les nitrates\n",
    "    process_data(filtered_df_hb_nitrate, \"Nitrate\", data_nitrate)\n",
    "\n",
    "    # Traiter les données pour l'oxygène dissous\n",
    "    process_data(filtered_df_hb_oxdissous, \"OxygeneDissous\", data_oxdissous)\n",
    "\n",
    "    # Traiter les données pour l'oxygène dissous\n",
    "    process_data(filtered_df_hb_dbo5, \"DBO5\", data_dbo5)\n",
    "\n",
    "    # Traiter les données pour l'oxygène dissous\n",
    "    process_data(filtered_df_hb_phosphore, \"Phosphore\", data_phosphore)\n",
    "\n",
    "    # Convertir les listes de résultats en DataFrame\n",
    "    nitrate_results = pd.DataFrame(data_nitrate)\n",
    "    oxdissous_results = pd.DataFrame(data_oxdissous)\n",
    "    dbo5_results = pd.DataFrame(data_dbo5)\n",
    "    phosphore_results = pd.DataFrame(data_phosphore)\n",
    "\n",
    "    # Fusionner les résultats pour les deux paramètres sur la station et la saison\n",
    "    merged_results = pd.merge(\n",
    "        nitrate_results,\n",
    "        oxdissous_results,\n",
    "        on=[\"CdStationMesureEauxSurface\", \"Saison\", \"measureFromHB\"],\n",
    "        how=\"outer\"\n",
    "    )\n",
    "\n",
    "    merged_results = pd.merge(\n",
    "        merged_results,\n",
    "        dbo5_results,\n",
    "        on=[\"CdStationMesureEauxSurface\", \"Saison\", \"measureFromHB\"],\n",
    "        how=\"outer\"\n",
    "    )\n",
    "    merged_results = pd.merge(\n",
    "        merged_results,\n",
    "        phosphore_results,\n",
    "        on=[\"CdStationMesureEauxSurface\", \"Saison\", \"measureFromHB\"],\n",
    "        how=\"outer\"\n",
    "    )\n",
    "\n",
    "    # Sauvegarder les résultats pour ce seuil HER\n",
    "    results_by_her[dftorec] = merged_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Afficher le dernier car j'ai referentiel dessus d'apres le reste du travail effectue\n",
    "results_by_her[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifications uniquement pour le HER20\n",
    "# results_by_her[20].isna().sum()\n",
    "# results_by_her[20].isnull()\n",
    "# results_by_her[20][results_by_her[20]['medianDBO5'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Vérifier les colonnes ayant des valeurs manquantes pour tous les datasets\n",
    "for i in her_thresholds:\n",
    "    for column in results_by_her[i].columns:\n",
    "        if results_by_her[i][column].isnull().any():  # Vérifier si la colonne contient des valeurs manquantes\n",
    "            median_value = results_by_her[i][column].median()  # Calculer la médiane de la colonne\n",
    "            results_by_her[i][column].fillna(median_value, inplace=True)  # Remplir les valeurs manquantes par la médiane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mettre sous forme de one hot les valeurs des saisons\n",
    "for i in her_thresholds:\n",
    "    results_by_her[i] = pd.get_dummies(results_by_her[i], columns=['Saison'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De maniere pratique, mettre le resultats a la fin \n",
    "for i in her_thresholds:\n",
    "    # Mettre en derniere position measureFromHB\n",
    "    columns = [col for col in results_by_her[i].columns if col != 'measureFromHB'] + ['measureFromHB']\n",
    "    results_by_her[i] = results_by_her[i][columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_by_her[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Importer les valeurs de Hydro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_hb_H20_resultats_clustering = pd.read_csv('./donnees/resultats_releves_H20_station_bonne-mauvaise.csv')\n",
    "print(df_hb_H20_resultats_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour afficher la taille du dataset importe\n",
    "print(df_hb_H20_resultats_clustering['CdStationMesureEauxSurface'].unique())\n",
    "print(df_hb_H20_resultats_clustering['CdStationMesureEauxSurface'].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ici le but est de recuperer tous les releves des memes stations que dans le H20\n",
    "# stations_pre_dataset = df_hb_H20_resultats_clustering[\"CdStationMesureEauxSurface\"].unique()\n",
    "# filtered_df = nitrate_new_data_filtered_cleaned[\n",
    "#     nitrate_new_data_filtered_cleaned[\"CdStationMesureEauxSurface\"].isin(stations_pre_dataset)\n",
    "# ]\n",
    "# print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1051 releves pour les memes stations que le H20\n",
    "# filtered_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour toutes les saisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pour le Nitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passage des valeurs de CdStationMesureEauxSurface en string qui est plus simple pour l'analyse (contient des 0 devant)\n",
    "nitrate_new_data_filtered_cleaned[\"CdStationMesureEauxSurface\"] = nitrate_new_data_filtered_cleaned[\"CdStationMesureEauxSurface\"].astype(str)\n",
    "\n",
    "df_hb_H20_resultats_clustering[\"CdStationMesureEauxSurface\"] = (\n",
    "    df_hb_H20_resultats_clustering[\"CdStationMesureEauxSurface\"]\n",
    "    .astype(str)\n",
    "    .str.zfill(8)  # Juste parceque les donnees venant de hb n'avait pas le 0 devant\n",
    ")\n",
    "\n",
    "stations_pre_dataset = df_hb_H20_resultats_clustering[\"CdStationMesureEauxSurface\"].unique()\n",
    "# Si des valeurs ont etes oublies\n",
    "# stations_pre_dataset = [\"0\" + station if not station.startswith(\"0\") else station for station in stations_pre_dataset]\n",
    "\n",
    "# Filtrer les lignes dans nitrate_new_data_filtered_cleaned en fonction des valeurs de stations_pre_dataset\n",
    "filtered_df_H20_hb_nitrate = nitrate_new_data_filtered_cleaned[\n",
    "    nitrate_new_data_filtered_cleaned[\"CdStationMesureEauxSurface\"].isin(stations_pre_dataset)\n",
    "]\n",
    "\n",
    "print(filtered_df_H20_hb_nitrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour recuperer uniquement les nitrates \n",
    "nitrate_new_data_filtered_cleaned = new_data_filtered_cleaned[new_data_filtered_cleaned['CdParametre'] == '1340']\n",
    "nitrate_new_data_filtered_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialisation de la liste pour stocker les résultats sous forme de données\n",
    "data = []\n",
    "\n",
    "# Boucle sur toutes les saisons disponibles\n",
    "for season in filtered_df_H20_hb_nitrate['LbSaison'].unique():\n",
    "    # Filtrer les données pour la saison actuelle\n",
    "    filtered_season_data = filtered_df_H20_hb_nitrate[filtered_df_H20_hb_nitrate['LbSaison'] == season]\n",
    "\n",
    "    # Assurer que les données sont en format datetime et triées par date\n",
    "    filtered_season_data[\"DatePrel\"] = pd.to_datetime(filtered_season_data[\"DatePrel\"])\n",
    "    filtered_season_data = filtered_season_data.sort_values(by=[\"DatePrel\"])\n",
    "\n",
    "    # Calcul de la médiane pour chaque station\n",
    "    for station, group in filtered_season_data.groupby(\"CdStationMesureEauxSurface\"):\n",
    "        # Calcul de la médiane des valeurs RsAna\n",
    "        median_value = group[\"RsAna\"].median()\n",
    "\n",
    "        # Récupérer la qualité pour l'affichage (la qualité est toujours la même pour la station)\n",
    "        tmp = df_hb_H20_resultats_clustering[df_hb_H20_resultats_clustering['CdStationMesureEauxSurface'] == station].iloc[0]\n",
    "\n",
    "        # Ajouter les résultats sous forme de ligne dans la liste de données\n",
    "        data.append({\n",
    "            \"CdStationMesureEauxSurface\": station,\n",
    "            \"Saison\": season,\n",
    "            \"medianNitrate\": median_value,\n",
    "            \"measureFromHB\": tmp['Qualite']\n",
    "        })\n",
    "\n",
    "        # Visualiser la série temporelle avec la médiane\n",
    "        # plt.figure()\n",
    "        # plt.plot(group[\"DatePrel\"], group[\"RsAna\"], label=\"Valeurs mesurées\")\n",
    "        # plt.axhline(y=median_value, color=\"red\", linestyle=\"--\", label=f\"Médiane: {median_value:.2f}\")\n",
    "        # plt.title(f\"Série temporelle pour la station {station} - Saison {season} (Qualité: {tmp['Qualite']})\")\n",
    "        # plt.xlabel(\"Date\")\n",
    "        # plt.ylabel(\"RsAna\")\n",
    "        # plt.legend()\n",
    "        # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Conversion de la liste de dictionnaires en DataFrame\n",
    "df_results_median_class_nitrate = pd.DataFrame(data)\n",
    "\n",
    "# Créer un DataFrame pivoté avec la saison comme colonnes et station comme index\n",
    "df_result_med_nitrate = df_results_median_class_nitrate.pivot_table(\n",
    "    index=\"CdStationMesureEauxSurface\",\n",
    "    columns=\"Saison\",\n",
    "    values=[\"medianNitrate\"],\n",
    "    aggfunc=\"first\"\n",
    ")\n",
    "\n",
    "# Extraire la qualité pour chaque station (elle est la même pour toutes les saisons)\n",
    "# df_quality = df_results_median_class_nitrate.drop_duplicates(subset=\"CdStationMesureEauxSurface\")[[\"CdStationMesureEauxSurface\", \"measureFromHB\"]]\n",
    "\n",
    "# Joindre la qualité au DataFrame pivoté\n",
    "# df_result_med_nitrate[\"measureFromHB\"] = df_quality.set_index(\"CdStationMesureEauxSurface\")[\"measureFromHB\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result_med_nitrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pour oxygène dissous "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour recuperer uniquement les nitrates \n",
    "oxdissous_new_data_filtered_cleaned = new_data_filtered_cleaned[new_data_filtered_cleaned['CdParametre'] == '1311']\n",
    "oxdissous_new_data_filtered_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passage des valeurs de CdStationMesureEauxSurface en string qui est plus simple pour l'analyse (contient des 0 devant)\n",
    "oxdissous_new_data_filtered_cleaned[\"CdStationMesureEauxSurface\"] = oxdissous_new_data_filtered_cleaned[\"CdStationMesureEauxSurface\"].astype(str)\n",
    "\n",
    "stations_pre_dataset = df_hb_H20_resultats_clustering[\"CdStationMesureEauxSurface\"].unique()\n",
    "\n",
    "# Filtrer les lignes dans nitrate_new_data_filtered_cleaned en fonction des valeurs de stations_pre_dataset\n",
    "filtered_df_H20_hb_oxdissous = oxdissous_new_data_filtered_cleaned[\n",
    "    oxdissous_new_data_filtered_cleaned[\"CdStationMesureEauxSurface\"].isin(stations_pre_dataset)\n",
    "]\n",
    "\n",
    "filtered_df_H20_hb_oxdissous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialisation de la liste pour stocker les résultats sous forme de données\n",
    "data = []\n",
    "\n",
    "# Boucle sur toutes les saisons disponibles\n",
    "for season in filtered_df_H20_hb_oxdissous['LbSaison'].unique():\n",
    "    # Filtrer les données pour la saison actuelle\n",
    "    filtered_season_data = filtered_df_H20_hb_oxdissous[filtered_df_H20_hb_oxdissous['LbSaison'] == season]\n",
    "\n",
    "    # Assurer que les données sont en format datetime et triées par date\n",
    "    filtered_season_data[\"DatePrel\"] = pd.to_datetime(filtered_season_data[\"DatePrel\"])\n",
    "    filtered_season_data = filtered_season_data.sort_values(by=[\"DatePrel\"])\n",
    "\n",
    "    # Calcul de la médiane pour chaque station\n",
    "    for station, group in filtered_season_data.groupby(\"CdStationMesureEauxSurface\"):\n",
    "        # Calcul de la médiane des valeurs RsAna\n",
    "        median_value = group[\"RsAna\"].median()\n",
    "\n",
    "        # Récupérer la qualité pour l'affichage (la qualité est toujours la même pour la station)\n",
    "        tmp = df_hb_H20_resultats_clustering[df_hb_H20_resultats_clustering['CdStationMesureEauxSurface'] == station].iloc[0]\n",
    "\n",
    "        # Ajouter les résultats sous forme de ligne dans la liste de données\n",
    "        data.append({\n",
    "            \"CdStationMesureEauxSurface\": station,\n",
    "            \"Saison\": season,\n",
    "            \"medianOxDissous\": median_value,\n",
    "            \"measureFromHB\": tmp['Qualite']\n",
    "        })\n",
    "\n",
    "        # Visualiser la série temporelle avec la médiane\n",
    "        # plt.figure()\n",
    "        # plt.plot(group[\"DatePrel\"], group[\"RsAna\"], label=\"Valeurs mesurées\")\n",
    "        # plt.axhline(y=median_value, color=\"red\", linestyle=\"--\", label=f\"Médiane: {median_value:.2f}\")\n",
    "        # plt.title(f\"Série temporelle pour la station {station} - Saison {season} (Qualité: {tmp['Qualite']})\")\n",
    "        # plt.xlabel(\"Date\")\n",
    "        # plt.ylabel(\"RsAna\")\n",
    "        # plt.legend()\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion de la liste de dictionnaires en DataFrame\n",
    "df_results_median_class_oxdissous = pd.DataFrame(data)\n",
    "\n",
    "# Créer un DataFrame pivoté avec la saison comme colonnes et station comme index\n",
    "df_result_med_oxdissous = df_results_median_class_oxdissous.pivot_table(\n",
    "    index=\"CdStationMesureEauxSurface\",\n",
    "    columns=\"Saison\",\n",
    "    values=[\"medianOxDissous\"],\n",
    "    aggfunc=\"first\"\n",
    ")\n",
    "\n",
    "# Extraire la qualité pour chaque station (elle est la même pour toutes les saisons)\n",
    "# df_quality = df_results_median_class_oxdissous.drop_duplicates(subset=\"CdStationMesureEauxSurface\")[[\"CdStationMesureEauxSurface\", \"measureFromHB\"]]\n",
    "\n",
    "# Joindre la qualité au DataFrame pivoté\n",
    "# df_result_med_oxdissous[\"measureFromHB\"] = df_quality.set_index(\"CdStationMesureEauxSurface\")[\"measureFromHB\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result_med_oxdissous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pour DBO5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour recuperer uniquement les nitrates \n",
    "dbo5_new_data_filtered_cleaned = new_data_filtered_cleaned[new_data_filtered_cleaned['CdParametre'] == '1313']\n",
    "dbo5_new_data_filtered_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passage des valeurs de CdStationMesureEauxSurface en string qui est plus simple pour l'analyse (contient des 0 devant)\n",
    "dbo5_new_data_filtered_cleaned[\"CdStationMesureEauxSurface\"] = dbo5_new_data_filtered_cleaned[\"CdStationMesureEauxSurface\"].astype(str)\n",
    "\n",
    "stations_pre_dataset = df_hb_H20_resultats_clustering[\"CdStationMesureEauxSurface\"].unique()\n",
    "\n",
    "# Filtrer les lignes dans nitrate_new_data_filtered_cleaned en fonction des valeurs de stations_pre_dataset\n",
    "filtered_df_H20_hb_dbo5 = dbo5_new_data_filtered_cleaned[\n",
    "    dbo5_new_data_filtered_cleaned[\"CdStationMesureEauxSurface\"].isin(stations_pre_dataset)\n",
    "]\n",
    "\n",
    "filtered_df_H20_hb_dbo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation de la liste pour stocker les résultats sous forme de données\n",
    "data = []\n",
    "\n",
    "# Boucle sur toutes les saisons disponibles\n",
    "for season in filtered_df_H20_hb_dbo5['LbSaison'].unique():\n",
    "    # Filtrer les données pour la saison actuelle\n",
    "    filtered_season_data = filtered_df_H20_hb_dbo5[filtered_df_H20_hb_dbo5['LbSaison'] == season]\n",
    "\n",
    "    # Assurer que les données sont en format datetime et triées par date\n",
    "    filtered_season_data[\"DatePrel\"] = pd.to_datetime(filtered_season_data[\"DatePrel\"])\n",
    "    filtered_season_data = filtered_season_data.sort_values(by=[\"DatePrel\"])\n",
    "\n",
    "    # Calcul de la médiane pour chaque station\n",
    "    for station, group in filtered_season_data.groupby(\"CdStationMesureEauxSurface\"):\n",
    "        # Calcul de la médiane des valeurs RsAna\n",
    "        median_value = group[\"RsAna\"].median()\n",
    "\n",
    "        # Récupérer la qualité pour l'affichage (la qualité est toujours la même pour la station)\n",
    "        tmp = df_hb_H20_resultats_clustering[df_hb_H20_resultats_clustering['CdStationMesureEauxSurface'] == station].iloc[0]\n",
    "\n",
    "        # Ajouter les résultats sous forme de ligne dans la liste de données\n",
    "        data.append({\n",
    "            \"CdStationMesureEauxSurface\": station,\n",
    "            \"Saison\": season,\n",
    "            \"medianDBO5\": median_value,\n",
    "            \"measureFromHB\": tmp['Qualite']\n",
    "        })\n",
    "\n",
    "        # Visualiser la série temporelle avec la médiane\n",
    "        # plt.figure()\n",
    "        # plt.plot(group[\"DatePrel\"], group[\"RsAna\"], label=\"Valeurs mesurées\")\n",
    "        # plt.axhline(y=median_value, color=\"red\", linestyle=\"--\", label=f\"Médiane: {median_value:.2f}\")\n",
    "        # plt.title(f\"Série temporelle pour la station {station} - Saison {season} (Qualité: {tmp['Qualite']})\")\n",
    "        # plt.xlabel(\"Date\")\n",
    "        # plt.ylabel(\"RsAna\")\n",
    "        # plt.legend()\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion de la liste de dictionnaires en DataFrame\n",
    "df_results_median_class_dbo5 = pd.DataFrame(data)\n",
    "\n",
    "# Créer un DataFrame pivoté avec la saison comme colonnes et station comme index\n",
    "df_result_med_dbo5 = df_results_median_class_dbo5.pivot_table(\n",
    "    index=\"CdStationMesureEauxSurface\",\n",
    "    columns=\"Saison\",\n",
    "    values=[\"medianDBO5\"],\n",
    "    aggfunc=\"first\"\n",
    ")\n",
    "\n",
    "# Extraire la qualité pour chaque station (elle est la même pour toutes les saisons)\n",
    "# df_quality = df_results_median_class_oxdissous.drop_duplicates(subset=\"CdStationMesureEauxSurface\")[[\"CdStationMesureEauxSurface\", \"measureFromHB\"]]\n",
    "\n",
    "# Joindre la qualité au DataFrame pivoté\n",
    "# df_result_med_dbo5[\"measureFromHB\"] = df_quality.set_index(\"CdStationMesureEauxSurface\")[\"measureFromHB\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_med_dbo5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pour le phosphore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour recuperer uniquement les nitrates \n",
    "phosphore_new_data_filtered_cleaned = new_data_filtered_cleaned[new_data_filtered_cleaned['CdParametre'] == '1350']\n",
    "phosphore_new_data_filtered_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passage des valeurs de CdStationMesureEauxSurface en string qui est plus simple pour l'analyse (contient des 0 devant)\n",
    "phosphore_new_data_filtered_cleaned[\"CdStationMesureEauxSurface\"] = phosphore_new_data_filtered_cleaned[\"CdStationMesureEauxSurface\"].astype(str)\n",
    "\n",
    "stations_pre_dataset = df_hb_H20_resultats_clustering[\"CdStationMesureEauxSurface\"].unique()\n",
    "\n",
    "# Filtrer les lignes dans nitrate_new_data_filtered_cleaned en fonction des valeurs de stations_pre_dataset\n",
    "filtered_df_H20_hb_phosphore = phosphore_new_data_filtered_cleaned[\n",
    "    phosphore_new_data_filtered_cleaned[\"CdStationMesureEauxSurface\"].isin(stations_pre_dataset)\n",
    "]\n",
    "\n",
    "filtered_df_H20_hb_phosphore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation de la liste pour stocker les résultats sous forme de données\n",
    "data = []\n",
    "\n",
    "# Boucle sur toutes les saisons disponibles\n",
    "for season in filtered_df_H20_hb_phosphore['LbSaison'].unique():\n",
    "    # Filtrer les données pour la saison actuelle\n",
    "    filtered_season_data = filtered_df_H20_hb_phosphore[filtered_df_H20_hb_phosphore['LbSaison'] == season]\n",
    "\n",
    "    # Assurer que les données sont en format datetime et triées par date\n",
    "    filtered_season_data[\"DatePrel\"] = pd.to_datetime(filtered_season_data[\"DatePrel\"])\n",
    "    filtered_season_data = filtered_season_data.sort_values(by=[\"DatePrel\"])\n",
    "\n",
    "    # Calcul de la médiane pour chaque station\n",
    "    for station, group in filtered_season_data.groupby(\"CdStationMesureEauxSurface\"):\n",
    "        # Calcul de la médiane des valeurs RsAna\n",
    "        median_value = group[\"RsAna\"].median()\n",
    "\n",
    "        # Récupérer la qualité pour l'affichage (la qualité est toujours la même pour la station)\n",
    "        tmp = df_hb_H20_resultats_clustering[df_hb_H20_resultats_clustering['CdStationMesureEauxSurface'] == station].iloc[0]\n",
    "\n",
    "        # Ajouter les résultats sous forme de ligne dans la liste de données\n",
    "        data.append({\n",
    "            \"CdStationMesureEauxSurface\": station,\n",
    "            \"Saison\": season,\n",
    "            \"medianPhosphore\": median_value,\n",
    "            \"measureFromHB\": tmp['Cluster']\n",
    "        })\n",
    "\n",
    "        # Visualiser la série temporelle avec la médiane\n",
    "        # plt.figure()\n",
    "        # plt.plot(group[\"DatePrel\"], group[\"RsAna\"], label=\"Valeurs mesurées\")\n",
    "        # plt.axhline(y=median_value, color=\"red\", linestyle=\"--\", label=f\"Médiane: {median_value:.2f}\")\n",
    "        # plt.title(f\"Série temporelle pour la station {station} - Saison {season} (Qualité: {tmp['Qualite']})\")\n",
    "        # plt.xlabel(\"Date\")\n",
    "        # plt.ylabel(\"RsAna\")\n",
    "        # plt.legend()\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion de la liste de dictionnaires en DataFrame\n",
    "df_results_median_class_phosphore = pd.DataFrame(data)\n",
    "\n",
    "# Créer un DataFrame pivoté avec la saison comme colonnes et station comme index\n",
    "df_result_med_phosphore = df_results_median_class_phosphore.pivot_table(\n",
    "    index=\"CdStationMesureEauxSurface\",\n",
    "    columns=\"Saison\",\n",
    "    values=[\"medianPhosphore\"],\n",
    "    aggfunc=\"first\"\n",
    ")\n",
    "\n",
    "# Extraire la qualité pour chaque station (elle est la même pour toutes les saisons)\n",
    "df_quality = df_results_median_class_phosphore.drop_duplicates(subset=\"CdStationMesureEauxSurface\")[[\"CdStationMesureEauxSurface\", \"measureFromHB\"]]\n",
    "\n",
    "# Joindre la qualité au DataFrame pivoté\n",
    "df_result_med_phosphore[\"measureFromHB\"] = df_quality.set_index(\"CdStationMesureEauxSurface\")[\"measureFromHB\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_med_phosphore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatener tous les datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_concats = pd.concat([df_result_med_oxdissous, df_result_med_nitrate, df_result_med_dbo5, df_result_med_phosphore], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_concats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_concats.columns = ['_'.join(col).strip() for col in results_concats.columns.values]\n",
    "results_concats.rename(columns={'measureFromHB_': 'measureFromHB'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_concats = results_concats.dropna(subset=['measureFromHB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_replace = results_concats.columns.difference(['measureFromHB'])\n",
    "# Remplacement des NaN par la moyenne\n",
    "results_concats[columns_to_replace] = results_concats[columns_to_replace].apply(\n",
    "    lambda col: col.fillna(col.mean())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_concats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "Pour determiner si on peut trouver des patterns dans les donnees, il faut utiliser un algorithme tel que XGboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separer le dataset en X et y pour travailler sur chaque partie\n",
    "X = results_concats.drop(['measureFromHB'], axis=1)\n",
    "y = results_concats['measureFromHB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split tres petit 80% train 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost sur toutes les HER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in her_thresholds:\n",
    "    # Vérification et nettoyage des données\n",
    "    if 'CdStationMesureEauxSurface' in results_by_her[i].columns:\n",
    "        results_by_her[i].drop(columns='CdStationMesureEauxSurface', inplace=True)\n",
    "\n",
    "    # Définir X (features) et y (target)\n",
    "    X = results_by_her[i].drop(['measureFromHB'], axis=1)\n",
    "    y = results_by_her[i]['measureFromHB']\n",
    "\n",
    "    # Séparer les données en ensembles d'entraînement et de test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Area Under the Curve (AUC) pour évaluer les performances d'un modèle en termes de séparation des classes.\n",
    "    # logloss : Logarithmic Loss (par défaut pour la classification binaire).\n",
    "    \n",
    "    # Instancier et entraîner le modèle XGBoost\n",
    "    model = XGBClassifier(\n",
    "        eval_metric='auc',  # Métrique de validation par défaut\n",
    "        use_label_encoder=False,  # Important pour éviter un warning avec les versions récentes\n",
    "        random_state=42          # Assurer la reproductibilité\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Prédictions et évaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'Resultats pour le HER {i}')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Importance des caractéristiques\n",
    "    importance = model.get_booster().get_score(importance_type='weight')  # 'gain', 'cover', ou 'weight'\n",
    "    print(\"Importance des caractéristiques :\", importance)\n",
    "\n",
    "    # Visualisation de l'importance des caractéristiques\n",
    "    xgb.plot_importance(model, importance_type='weight')  # Peut être changé en 'gain' ou 'cover'\n",
    "    plt.title(f'Importance des caractéristiques pour le HER {i}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "# Paramètres pour RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 1, 5],\n",
    "    'reg_alpha': [0, 1, 10],\n",
    "    'reg_lambda': [1, 10, 50],\n",
    "}\n",
    "\n",
    "# Boucle pour chaque HER\n",
    "for i in her_thresholds:\n",
    "    print(f'--- Traitement pour le HER {i} ---')\n",
    "\n",
    "    # Vérifier la colonne spécifique et la retirer si elle existe\n",
    "    if 'CdStationMesureEauxSurface' in results_by_her[i].columns:\n",
    "        results_by_her[i].drop(columns='CdStationMesureEauxSurface', inplace=True)\n",
    "\n",
    "    X = results_by_her[i].drop(['measureFromHB'], axis=1)\n",
    "    y = results_by_her[i]['measureFromHB']\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Modèle XGBoost\n",
    "    model = XGBClassifier(eval_metric='mlogloss', use_label_encoder=False)\n",
    "\n",
    "    # Configuration de RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=50,  # Nombre d'itérations aléatoires\n",
    "        scoring='f1_macro',  # Métrique utilisée\n",
    "        cv=3,  # Validation croisée à 3 plis\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Entraîner le modèle avec RandomizedSearch\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Meilleurs paramètres\n",
    "    print(\"Meilleurs paramètres :\", random_search.best_params_)\n",
    "    print(\"Meilleur score (validation croisée) :\", random_search.best_score_)\n",
    "\n",
    "    # Évaluer sur les données de test\n",
    "    best_model = random_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    print(f'Classification Report pour le HER {i}:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Importance des caractéristiques\n",
    "    importance = best_model.get_booster().get_score(importance_type='weight')\n",
    "    print(f'Importance des caractéristiques pour le HER {i} : {importance}')\n",
    "\n",
    "    # Visualiser l'importance des caractéristiques\n",
    "    xgb.plot_importance(best_model, importance_type='weight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'medianOxygeneDissous' in results_by_her[20].columns:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Uniquement pour ete (Ne pas faire tourner, precedent avec toutes les saisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour simplifier on ne prend que l'ete pour le moment\n",
    "# filtered_df_H20_hb_nitrate_Ete = filtered_df_H20_hb_nitrate[filtered_df_H20_hb_nitrate['LbSaison'] == 'Ete']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mettre le dataset en date time pour etre sur que c'est bien dans l'ordre chronologique (n'a finalement pas d'utilite)\n",
    "# filtered_df_H20_hb_nitrate_Ete[\"DatePrel\"] = pd.to_datetime(filtered_df_H20_hb_nitrate_Ete[\"DatePrel\"])\n",
    "# filtered_df_H20_hb_nitrate_Ete = filtered_df_H20_hb_nitrate_Ete.sort_values(by=[\"DatePrel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df_H20_hb_nitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df_H20_hb_nitrate_Ete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tres interessant mais la regression n'a certainement pas d'interet. La mediane semble etre plus utile.\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# # Calcul de la tendance pour chaque station\n",
    "# results = {}\n",
    "# for station, group in filtered_df_H20_hb_nitrate_Ete.groupby(\"CdStationMesureEauxSurface\"):\n",
    "#     # Convertir les dates en valeurs numériques pour la régression\n",
    "#     group[\"DateNum\"] = (group[\"DatePrel\"] - group[\"DatePrel\"].min()).dt.days\n",
    "    \n",
    "#     # Modèle de régression linéaire\n",
    "#     X = group[\"DateNum\"].values.reshape(-1, 1)\n",
    "#     y = group[\"RsAna\"].values\n",
    "#     model = LinearRegression().fit(X, y)\n",
    "    \n",
    "#     # Stocker les résultats\n",
    "#     results[station] = {\n",
    "#         \"slope\": model.coef_[0],\n",
    "#         \"intercept\": model.intercept_,\n",
    "#         \"trend_line\": model.predict(X),\n",
    "#     }\n",
    "#     tmp = df_hb_H20_resultats_clustering[df_hb_H20_resultats_clustering['CdStationMesureEauxSurface'] == station].iloc[0]\n",
    "    \n",
    "#     # Visualiser la série temporelle\n",
    "#     plt.figure()\n",
    "#     plt.plot(group[\"DatePrel\"], group[\"RsAna\"], label=\"Valeurs mesurées\")\n",
    "#     plt.plot(group[\"DatePrel\"], results[station][\"trend_line\"], label=\"Tendance\", linestyle=\"--\")\n",
    "#     plt.title(f\"Série temporelle pour la station {station} (de base dit {tmp['Qualite']})\")\n",
    "#     plt.xlabel(\"Date\")\n",
    "#     plt.ylabel(\"RsAna\")\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calcul de la médiane pour chaque station\n",
    "# results_median_class_nitrate = {}\n",
    "# for station, group in filtered_df_H20_hb_nitrate_Ete.groupby(\"CdStationMesureEauxSurface\"):\n",
    "#     # Calcul de la médiane des valeurs RsAna\n",
    "#     median_value = group[\"RsAna\"].median()\n",
    "\n",
    "#     # Récupérer la qualité pour l'affichage\n",
    "#     tmp = df_hb_H20_resultats_clustering[df_hb_H20_resultats_clustering['CdStationMesureEauxSurface'] == station].iloc[0]\n",
    "    \n",
    "#     # Stocker les résultats\n",
    "#     results_median_class_nitrate[station] = {\n",
    "#         \"medianNitrate\": median_value,\n",
    "#         \"measureFromHB\": tmp['Qualite']\n",
    "#     }\n",
    "    \n",
    "#     # Visualiser la série temporelle avec la médiane\n",
    "#     plt.figure()\n",
    "#     plt.plot(group[\"DatePrel\"], group[\"RsAna\"], label=\"Valeurs mesurées\")\n",
    "#     plt.axhline(y=median_value, color=\"red\", linestyle=\"--\", label=f\"Médiane: {median_value:.2f}\")\n",
    "#     plt.title(f\"Série temporelle pour la station {station} (de base dit {tmp['Qualite']})\")\n",
    "#     plt.xlabel(\"Date\")\n",
    "#     plt.ylabel(\"RsAna\")\n",
    "#     plt.legend()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_median_class_nitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour ajouter si bon ou mauvais\n",
    "# Extraire la qualité pour chaque station (elle est la même pour toutes les saisons)\n",
    "# df_quality = df_results_median_class_nitrate.drop_duplicates(subset=\"CdStationMesureEauxSurface\")[[\"CdStationMesureEauxSurface\", \"measureFromHB\"]]\n",
    "\n",
    "# Joindre la qualité au DataFrame pivoté\n",
    "# df_result_med_nitrate[\"measureFromHB\"] = df_quality.set_index(\"CdStationMesureEauxSurface\")[\"measureFromHB\"]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Chaima_Naiade_4",
   "language": "python",
   "name": "chaima_naiade_4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
